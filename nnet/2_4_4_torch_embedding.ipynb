{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4.4. Нейросетевая модель torch.embedding.  \n",
    "\n",
    "\n",
    "Видеоуроки:  \n",
    "2.4.1. Векторное представление единиц текста.  \n",
    "2.4.2. Обучение нейросетевой модели word2vec.  \n",
    "2.4.3. Использование обученных моделей RusVectōrēs.  \n",
    "**2.4.4. Нейросетевая модель torch.embedding.**  \n",
    "\n",
    "Дополнительные материалы:  \n",
    "2.4.5. Использование обученных моделей RusVectōrēs для классификации (анализа тональности) текста.  \n",
    "2.4.6. Использование моделей Hugging Face для классификации (анализа тональности) текста.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import logging\n",
    "from utils import reset_random_seeds\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.decomposition import PCA\n",
    "from string import punctuation\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "reset_random_seeds(RANDOM_SEED)\n",
    "plt.style.use('ggplot')\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в случае с бинарным (OneHot) кодированием, (где слова представляются в виде вектора, с 0 на всех позициях, кроме индекса заданного слова, равного 1), нам нужно задать индекс для каждого слова словаря. Это можно сравнить в с ключами в таблице поиска. Все эмбеддинги слов словаря сохраняются в матрице размера $|V| x D$, где $|V|$ - количество слов словаря, $D$ - размер эмбеддинга (выходного вектора). Слово с индексом $i$ будет сохранено в $i$ строке этой матрицы.  \n",
    "`torch.nn.Embeddings` - модуль, который позволяет вам использовать эмбеддинги. Принимает 2 параметра - размер словаря и размер эмбеддинга.  \n",
    "В словаре `word_to_ix` сохраним соответствие слов их индексам.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {'привет': 0, 'мир': 1}\n",
    "embeds = nn.Embedding(2, 5)  # 2 слова в словаре, 5 - размер эмбеддинга\n",
    "\n",
    "lookup_tensor = torch.tensor([word_to_ix['привет']], dtype=torch.long)\n",
    "\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "\n",
    "print(hello_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-граммная языковая модель.  \n",
    "\n",
    "В n-граммной языковой модели, наша задача - посчитать вероятность $w$ при учете контекста:  \n",
    "\n",
    "$P(w_i∣w_i−1,w_i−2,…,w_i−n+1)$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_to_ix: {'корова': 0, 'собака': 1, 'ест': 2, 'корм': 3, 'овца': 4, 'лугу': 5, 'щиплет': 6, 'на': 7, 'травку': 8, 'сухой': 9, 'кошка': 10}\n",
      "vocab_size: 11\n",
      "[(['корова', 'лугу', 'на'], 'щиплет'), (['щиплет', 'корова', 'лугу'], 'травку'), (['овца', 'лугу', 'на'], 'щиплет')]\n"
     ]
    }
   ],
   "source": [
    "def delete_punctuation(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Удаление стоп-слов.\n",
    "\n",
    "    Args:\n",
    "        text (str): Исходный текст.\n",
    "    Returns:\n",
    "        str: Обработанный текст.\n",
    "    \"\"\"\n",
    "\n",
    "    return ' '.join([t for t in text.split() if t not in punctuation])\n",
    "\n",
    "corpora = [\n",
    "    'На лугу корова щиплет травку',\n",
    "    'На лугу овца щиплет травку',\n",
    "    'Собака ест сухой корм',\n",
    "    'Кошка ест сухой корм',\n",
    "]\n",
    "\n",
    "text_processors = [\n",
    "    str.lower,\n",
    "    delete_punctuation,\n",
    "]\n",
    "\n",
    "for proc in text_processors:\n",
    "    for i, text in enumerate(corpora):\n",
    "        corpora[i] = proc(text)\n",
    "\n",
    "tokenized_corpora = [text.split() for text in corpora]\n",
    "\n",
    "vocab = set([tokens for sentence in tokenized_corpora for tokens in sentence])\n",
    "\n",
    "word_to_ix = {w: idx for (idx, w) in enumerate(vocab)}\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print('word_to_ix:', word_to_ix)\n",
    "print('vocab_size:', vocab_size)\n",
    "\n",
    "CONTEXT_SIZE = 3\n",
    "EMBEDDING_DIM = 4\n",
    "\n",
    "ngrams = [\n",
    "    (\n",
    "        [sent[i - j - 1] for j in range(CONTEXT_SIZE)],\n",
    "        sent[i]\n",
    "    )\n",
    "    for sent in tokenized_corpora\n",
    "    for i in range(CONTEXT_SIZE, len(sent))\n",
    "]\n",
    "\n",
    "# Print the first 3, just so you can see what they look like.\n",
    "print(ngrams[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epo 0: 15.453016757965088\n",
      "Loss at epo 50: 7.888537764549255\n",
      "Loss at epo 100: 4.159153550863266\n",
      "Loss at epo 150: 2.497830167412758\n",
      "Loss at epo 200: 1.6649567261338234\n",
      "Loss at epo 250: 1.190372534096241\n",
      "Loss at epo 300: 0.8942529186606407\n",
      "Loss at epo 350: 0.698239354416728\n",
      "Loss at epo 400: 0.5627048444002867\n",
      "Loss at epo 450: 0.46552196331322193\n"
     ]
    }
   ],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size: int, embedding_dim: int, context_size: int):\n",
    "        \"\"\"\n",
    "        N-граммная языковая модель.\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): размер словаря.\n",
    "            embedding_dim (int): размер эмбеддинга.\n",
    "            context_size (int): размер контекстного окна.\n",
    "        \"\"\"\n",
    "\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "N_EPOCHS = 500\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_loss = 0\n",
    "    for context, target in ngrams:\n",
    "\n",
    "        # Шаг 1. Подготовка данных на вход модели (переводим слова в индексы и оборачиваем в тензоры)\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "\n",
    "        # Шаг 2. PyTorch запоминает предыдущие градиенты. Перед новой итерацией вы должны обнулить их.\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Шаг 3. Запускаем прямое прохождение сети, получем логарифм вероятности для следующих слов.\n",
    "        log_probs = model(context_idxs)\n",
    "\n",
    "        # Шаг 4. Вычисляем функцию потерь.\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "\n",
    "        # Шаг 5. Запускаем обратный проход и обновляем градиенты.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Loss at epo {epoch}: {total_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(v: torch.Tensor, u: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Вычисление меры близости - косинусное расстояние.\"\"\"\n",
    "    return torch.dot(v,u) / (torch.norm(v)*torch.norm(u))\n",
    "\n",
    "\n",
    "def vectorize(word: str) -> torch.Tensor:\n",
    "    \"\"\"Получить вектор текста.\"\"\"\n",
    "    return model.embeddings.weight[word_to_ix[word]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8783, -1.3238,  0.5751,  2.6152], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выведем эмбеддинг какого-нибудь слова.\n",
    "vectorize('корова')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на близость слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово           Сосед           Расстояние     \n",
      "---------------------------------------------\n",
      "корова          корова          1.0\n",
      "корова          корм            0.64\n",
      "корова          овца            0.5\n",
      "\n",
      "овца            овца            1.0\n",
      "овца            на              0.79\n",
      "овца            корм            0.69\n",
      "\n",
      "собака          собака          1.0\n",
      "собака          травку          0.72\n",
      "собака          ест             0.67\n",
      "\n",
      "кошка           кошка           1.0\n",
      "кошка           лугу            0.39\n",
      "кошка           травку          0.34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# {word: [(word, similarity)]}\n",
    "results = {}\n",
    "\n",
    "words = 'корова овца собака кошка'.split(' ')\n",
    "for w1 in words:\n",
    "    results[w1] = []\n",
    "    for w2 in vocab:\n",
    "        w1v = vectorize(w1)\n",
    "        w2v = vectorize(w2)\n",
    "        d = similarity(w1v, w2v).item()\n",
    "        results[w1].append((w2, d))\n",
    "\n",
    "    results[w1] = sorted(results[w1], key=lambda item: item[1], reverse=True)\n",
    "\n",
    "col_width = 15\n",
    "print(*[c.ljust(col_width) for c in ['Слово', 'Сосед', 'Расстояние']])\n",
    "print('-'*col_width*3)\n",
    "\n",
    "for w1 in results:\n",
    "    for i in range(3):\n",
    "        d = round(results[w1][i][1], 2)\n",
    "        print(w1.ljust(col_width), results[w1][i][0].ljust(col_width), d)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "корова овца\n",
      "\n",
      "овца корова\n",
      "\n",
      "собака кошка\n",
      "\n",
      "кошка собака\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w_vects = [vectorize(w) for w in words]\n",
    "neighbors = []\n",
    "for v1 in w_vects:\n",
    "    dist = []\n",
    "    for v2, w2 in zip(w_vects, words):\n",
    "        d = similarity(v1, v2).item()\n",
    "        dist.append((d, w2))\n",
    "    dist = sorted(dist, key=lambda d: d[0], reverse=True)\n",
    "    n = dist[1][1]\n",
    "    neighbors.append(n)\n",
    "\n",
    "for w, n in zip(words, neighbors):\n",
    "    print(w, n)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И выведем на графике несколько слов, предварительно уменьшив размерность векторов слов методом главных компонент:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = 'корова овца собака кошка'.split(' ')\n",
    "xs = [model.embeddings.weight[word_to_ix[w]].detach().tolist() for w in words]\n",
    "xs_r = PCA(n_components=2).fit(xs).transform(xs)\n",
    "\n",
    "plt.figure()\n",
    "colors = ['navy', 'turquoise', 'orange', 'red']\n",
    "lw = 2\n",
    "\n",
    "# for color, word in zip(colors, words):\n",
    "for i, word in enumerate(words):\n",
    "    color = colors[i]\n",
    "    plt.scatter(\n",
    "        xs_r[i][0],\n",
    "        xs_r[i][1],\n",
    "        color=color,\n",
    "        alpha=0.8,\n",
    "        lw=lw,\n",
    "        label=word,\n",
    "    )\n",
    "plt.legend(loc=\"best\", shadow=False, scatterpoints=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d42e0e22d4c8d5b707481f6163680948cfaa890c6a848f9a148a54488fb6b32d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
