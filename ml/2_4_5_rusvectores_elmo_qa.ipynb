{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4.4. Оценка семантической близости вопросов и ответов с использованием модели Elmo сервиса RusVectōrēs.  \n",
    "\n",
    "Видеоуроки:  \n",
    "2.4.1. Векторное представление единиц текста.  \n",
    "2.4.2. Оценка близости двух текстов.  \n",
    "2.4.3. Модель word2vec сервиса RusVectōrēs.  \n",
    "\n",
    "Дополнительные материалы:  \n",
    "2.4.4. Скринкаст \"Оценка семантической близости вопросов и ответов с использованием модели FastText сервиса RusVectōrēs\".  \n",
    "**2.4.5. Скринкаст \"Оценка семантической близости вопросов и ответов с использованием модели Elmo сервиса RusVectōrēs\".**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В предыдущем уроке мы рассмотрели использование предобученной модели FastText сервиса RusVectores. FastText обучается на побуквенных н-граммах, позволяя таким образом обрабатывать слова, которых не было в обучающих примерах.  \n",
    "У модели FastText (как и Word2vec) есть один недостаток - так как модели обучаются выдавать вектор слова в соответствии с контекстом, в которых оно встречалось, то мы получаем некий усредненный контекст слова. Например в 2 текстах \"гриф гитары\" и \"гриф и имеет острый клюв\", \"смыслом\" слово гриф будет что-то среднее между гитарой и птицей. Эти модели не учитывают различия в контексте. И для слова гриф, вне зависимоси от конекста, модель всегда будет выдавать одинаковый вектор.  \n",
    "Решить эту проблему пытались как минимум с 2015 года. Сейчас господствующая парадигма в NLP такова: необходимо учитывать контекст не только при обучении моделей, но и при генерации векторов в практических приложениях. Ведь мы, люди, решаем, в каком именно значении употреблено слово, на основании других слов вокруг него.  \n",
    "То есть, на вход модели должно поступать не одно изолированное слово, а последовательность слов (например, предложение). Модель обрабатывает его целиком и генерирует для каждого слова его вектор, учитывая текущий контекст. Таким образом, в предложениях \"гриф гитары\" и \"гриф имеет острый клюв\" для слова \"гриф\" будут сгенерированы два разных вектора.  \n",
    "\n",
    "Подобные модели называются \"контекстуализированными\" (contextualized embeddings) и являются сейчас новым стандартом в автоматической обработке текста. На сайте проекта [RusVectōrēs](https://rusvectores.org/ru/models/) вы можете скачать модели обученные при помощи алгоритма Embeddings from Language Models (ELMo).  \n",
    "Описание алгоритма - в статье Мэттью Петерса и других [\"Deep contextualized word representations\"](https://aclweb.org/anthology/N18-1202).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы с моделями ELMo написана библиотека (simple elmo)[https://github.com/ltgoslo/simple_elmo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем все необходимые зависимости.\n",
    "import warnings\n",
    "import logging\n",
    "from typing import Dict, List\n",
    "import zipfile\n",
    "import wget\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "import simple_elmo\n",
    "\n",
    "\n",
    "# Общие настройки.\n",
    "plt.style.use('ggplot')\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В папке `'./data/volgatech_faq'` представлен датасет:  \n",
    "Описание файлов данных:  \n",
    "    `questions.csv` - вопросы пользователей;  \n",
    "    `answers.csv` - ответы на вопросы;  \n",
    "    `pos_relations.csv` - правильные ответы на вопросы (пары вопрос==ответ);  \n",
    "    `neg_relations.csv` - неправильные (неподходящие) ответы.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers.csv       neg_relations.csv questions.csv\n",
      "data.zip          pos_relations.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ./data/volgatech_faq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3647</td>\n",
       "      <td>размерность векторного пространства</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3644</td>\n",
       "      <td>расстояние</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3643</td>\n",
       "      <td>привет</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3631</td>\n",
       "      <td>что такое подпространство</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3630</td>\n",
       "      <td>матрица перехода к новому базису</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                 text\n",
       "0  3647  размерность векторного пространства\n",
       "1  3644                           расстояние\n",
       "2  3643                               привет\n",
       "3  3631            что такое подпространство\n",
       "4  3630     матрица перехода к новому базису"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions = pd.read_csv('./data/volgatech_faq/questions.csv', sep=';', names=['id', 'text'])\n",
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посчитаем количество уникальных текстов\n",
    "df_questions['text'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>339</td>\n",
       "      <td>Размерностью векторного пространства (ВП) назы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>358</td>\n",
       "      <td>С Евклидовым расстоянием мы с вами хорошо знак...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>383</td>\n",
       "      <td>Данный форум не предназначен для решения орган...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>384</td>\n",
       "      <td>Данный форум не предназначен для решения орган...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>Опр. Подпространством линейного пространства V...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               text\n",
       "0  339  Размерностью векторного пространства (ВП) назы...\n",
       "1  358  С Евклидовым расстоянием мы с вами хорошо знак...\n",
       "2  383  Данный форум не предназначен для решения орган...\n",
       "3  384  Данный форум не предназначен для решения орган...\n",
       "4  374  Опр. Подпространством линейного пространства V..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers = pd.read_csv('./data/volgatech_faq/answers.csv', sep=';', names=['id', 'text'])\n",
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посчитаем количество уникальных текстов\n",
    "df_answers['text'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для удобства работы далее нам нужно отсортировать значения таблиц вопросов и ответов по колонке 'id'\n",
    "\n",
    "df_answers = df_answers.sort_values(by=['id'], axis=0, ignore_index=True)\n",
    "df_questions = df_questions.sort_values(by=['id'], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>327</td>\n",
       "      <td>Векторные пространства, в которых задано скаля...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>329</td>\n",
       "      <td>А сейчас отметим следующее, что, задав скалярн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>331</td>\n",
       "      <td>Это поле рациональных чисел, с которыми мы фак...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>334</td>\n",
       "      <td>Давайте введем понятие абстрактного векторного...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>336</td>\n",
       "      <td>Кроме геометрических векторов - направленных о...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               text\n",
       "0  327  Векторные пространства, в которых задано скаля...\n",
       "1  329  А сейчас отметим следующее, что, задав скалярн...\n",
       "2  331  Это поле рациональных чисел, с которыми мы фак...\n",
       "3  334  Давайте введем понятие абстрактного векторного...\n",
       "4  336  Кроме геометрических векторов - направленных о..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_answers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3647</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3644</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3643</td>\n",
       "      <td>383,384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3631</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3630</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question   answer\n",
       "0      3647      339\n",
       "1      3644      358\n",
       "2      3643  383,384\n",
       "3      3631      374\n",
       "4      3630      405"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_positive = pd.read_csv('./data/volgatech_faq/pos_relations.csv', sep=';', names=['question', 'answer'])\n",
    "df_positive.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных 1 вопросу может соотвествовать несколько ответов.  \n",
    "Изменим данные - так чтобы 1 вопросу соответствовал 1 ответ для упрощения нашего учебного примера, оставим только первый ответ.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive['answer_1'] = df_positive['answer'].apply(lambda t: [int(a.strip()) for a in t.split(',')][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3647</td>\n",
       "      <td>339</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3644</td>\n",
       "      <td>358</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3643</td>\n",
       "      <td>383,384</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3631</td>\n",
       "      <td>374</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3630</td>\n",
       "      <td>405</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question   answer  answer_1\n",
       "0      3647      339       339\n",
       "1      3644      358       358\n",
       "2      3643  383,384       383\n",
       "3      3631      374       374\n",
       "4      3630      405       405"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_positive.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачаем модель, обученную на НКРЯ и Википедии (По сравнению с другими моделями на сайте проекта, тексты Википедии наиболее близки по теме к текстам нашего датасета).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_URL = 'http://vectors.nlpl.eu/repository/20/195.zip'\n",
    "\n",
    "model_arch_file = MODEL_URL.split('/')[-1]\n",
    "model_path = model_arch_file.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скачивание модели.\n",
    "# размер файла - 200 Mb.\n",
    "# Не выполняйте этот код повторно, если модель уже скачана и распакована.\n",
    "\n",
    "# _ = wget.download(MODEL_URL)\n",
    "# print(f'extract {model_arch_file} to path: {model_path}')\n",
    "# with zipfile.ZipFile(model_arch_file, 'r') as archive:\n",
    "#     zipfile.ZipFile.extractall(archive, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-12 19:51:04,146 : INFO : Loading model from 195...\n",
      "2022-02-12 19:51:04,149 : INFO : We will cache the vocabulary of 100 tokens.\n",
      "2022-02-12 19:51:05.776497: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-02-12 19:51:05.804423: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa0cf540b50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-02-12 19:51:05.804440: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default() as elmo_graph:\n",
    "    elmo_model = simple_elmo.ElmoModel()\n",
    "    elmo_model.load(model_path)\n",
    "\n",
    "with elmo_graph.as_default() as current_graph:\n",
    "    tf_session = tf.compat.v1.Session(graph=elmo_graph)\n",
    "    with tf_session.as_default() as sess:\n",
    "        elmo_model.elmo_sentence_input = simple_elmo.elmo.weight_layers(\"input\", elmo_model.sentence_embeddings_op)\n",
    "        sess.run(tf.compat.v1.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-12 19:51:15,667 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:51:16,947 : INFO : Warming up finished.\n",
      "2022-02-12 19:51:16,948 : INFO : Texts in the current batch: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: что такое евклидово пространство\n",
      "размер вектора: 1024\n",
      "vector: [0.0545633907652542, -0.01873746147080428, -0.08078931645565482, '...', 0.08553287328671184, -0.013187009387740055, 0.01673472377782036]\n"
     ]
    }
   ],
   "source": [
    "def get_text_vectors(texts: List[str]):\n",
    "    \"\"\"Получить вектор текста.\"\"\"\n",
    "\n",
    "    return elmo_model.get_elmo_vector_average(texts, session=tf_session)\n",
    "\n",
    "t = df_questions['text'].values[0]\n",
    "v = get_text_vectors([t])[0]\n",
    "print('text:', t)\n",
    "print('размер вектора:', v.size)\n",
    "print('vector:', list(v[:3]) + ['...'] + list(v[-3:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем самый простой подход - посчитаем косинусное расстояние между парами вопрос/ответ.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы не считать вектора текстов каждый раз - сохраним их в датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-12 19:51:20,517 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:51:22,316 : INFO : Warming up finished.\n",
      "2022-02-12 19:51:22,318 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:51:24,291 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:51:26,336 : INFO : Warming up finished.\n",
      "2022-02-12 19:51:26,339 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:51:28,346 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:51:30,905 : INFO : Warming up finished.\n",
      "2022-02-12 19:51:30,909 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:51:33,483 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:51:39,779 : INFO : Warming up finished.\n",
      "2022-02-12 19:51:39,787 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:51:46,455 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:51:52,552 : INFO : Warming up finished.\n",
      "2022-02-12 19:51:52,561 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:51:58,728 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:52:00,987 : INFO : Warming up finished.\n",
      "2022-02-12 19:52:00,992 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:52:03,748 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:52:08,101 : INFO : Warming up finished.\n",
      "2022-02-12 19:52:08,108 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:52:12,036 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:52:23,327 : INFO : Warming up finished.\n",
      "2022-02-12 19:52:23,338 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:52:34,418 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:52:39,217 : INFO : Warming up finished.\n",
      "2022-02-12 19:52:39,223 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:52:44,149 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:52:46,318 : INFO : Warming up finished.\n",
      "2022-02-12 19:52:46,321 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:52:48,500 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:52:58,864 : INFO : Warming up finished.\n",
      "2022-02-12 19:52:58,876 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:53:09,260 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:53:11,279 : INFO : Warming up finished.\n",
      "2022-02-12 19:53:11,282 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:53:13,252 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:53:18,972 : INFO : Warming up finished.\n",
      "2022-02-12 19:53:18,979 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:53:24,734 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:53:27,439 : INFO : Warming up finished.\n",
      "2022-02-12 19:53:27,443 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:53:30,075 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:53:35,196 : INFO : Warming up finished.\n",
      "2022-02-12 19:53:35,202 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:53:40,123 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:53:46,600 : INFO : Warming up finished.\n",
      "2022-02-12 19:53:46,608 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:53:53,161 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:53:57,725 : INFO : Warming up finished.\n",
      "2022-02-12 19:53:57,731 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:54:02,399 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:54:07,141 : INFO : Warming up finished.\n",
      "2022-02-12 19:54:07,147 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:54:11,806 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:54:13,684 : INFO : Warming up finished.\n",
      "2022-02-12 19:54:13,688 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:54:15,554 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:54:19,993 : INFO : Warming up finished.\n",
      "2022-02-12 19:54:19,998 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:54:24,429 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:54:33,264 : INFO : Warming up finished.\n",
      "2022-02-12 19:54:33,275 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:54:41,565 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:54:46,531 : INFO : Warming up finished.\n",
      "2022-02-12 19:54:46,539 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:54:51,782 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:54:52,863 : INFO : Warming up finished.\n",
      "2022-02-12 19:54:52,865 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:54:53,923 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:54:54,200 : INFO : Warming up finished.\n",
      "2022-02-12 19:54:54,201 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:54:54,481 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:54:57,145 : INFO : Warming up finished.\n",
      "2022-02-12 19:54:57,149 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:54:59,799 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:55:02,217 : INFO : Warming up finished.\n",
      "2022-02-12 19:55:02,221 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:55:04,635 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:55:13,624 : INFO : Warming up finished.\n",
      "2022-02-12 19:55:13,634 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:55:22,866 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:55:25,175 : INFO : Warming up finished.\n",
      "2022-02-12 19:55:25,179 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:55:27,432 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:55:28,413 : INFO : Warming up finished.\n",
      "2022-02-12 19:55:28,415 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:55:29,401 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:55:30,688 : INFO : Warming up finished.\n",
      "2022-02-12 19:55:30,690 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:55:31,961 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:55:39,710 : INFO : Warming up finished.\n",
      "2022-02-12 19:55:39,724 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:55:48,197 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:55:56,621 : INFO : Warming up finished.\n",
      "2022-02-12 19:55:56,630 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:04,761 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:04,973 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:04,974 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:05,197 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:05,562 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:05,563 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:05,924 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:06,143 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:06,144 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:06,365 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:06,523 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:06,524 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:06,673 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:06,967 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:06,968 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:07,252 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:07,645 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:07,647 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:08,023 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:08,488 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:08,490 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:08,970 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:09,267 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:09,268 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:09,563 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:09,817 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:09,818 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:10,104 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:10,454 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:10,455 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:10,776 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:11,056 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:11,057 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:11,318 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:11,596 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:11,597 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:11,872 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:12,091 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:12,092 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:12,319 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:12,590 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:12,591 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:12,966 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:13,344 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:13,345 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:13,706 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:14,036 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:14,037 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:14,326 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:14,544 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:14,545 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:14,778 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:14,971 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:14,972 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:15,160 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:15,412 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:15,413 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:15,667 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:15,956 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:15,958 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:16,219 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:16,740 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:16,741 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:17,247 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:17,425 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:17,426 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:17,595 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:17,796 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:17,797 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:18,010 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:18,168 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:18,169 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:18,326 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:18,493 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:18,494 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:18,670 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:18,846 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:18,848 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:19,012 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:19,174 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:19,175 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:19,340 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:19,504 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:19,504 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:19,685 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:19,785 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:19,786 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:19,877 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:20,025 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:20,026 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:20,180 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:20,271 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:20,272 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:20,361 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:20,524 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:20,525 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:20,676 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:20,812 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:20,813 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:20,957 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:21,144 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:21,146 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:21,372 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:21,428 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:21,429 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:21,497 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:21,598 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:21,600 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:21,687 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:21,850 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:21,851 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:22,019 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:22,172 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:22,173 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:22,337 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:22,538 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:22,539 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:22,741 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:22,908 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:22,909 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:23,091 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:23,302 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:23,303 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:23,501 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:23,694 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:23,695 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:23,892 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:24,013 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:24,014 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:24,130 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:24,231 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:24,232 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:24,315 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:24,450 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:24,451 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:24,583 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:24,713 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:24,714 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:24,849 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:24,978 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:24,979 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:25,119 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:25,314 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:25,315 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:25,504 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:25,639 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:25,641 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:25,789 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:25,948 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:25,949 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:26,116 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:26,271 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:26,272 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:26,437 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:26,609 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:26,610 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:26,774 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:26,939 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:26,941 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:27,119 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:27,280 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:27,281 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:27,443 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:27,600 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:27,601 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:27,773 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:27,933 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:27,934 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:28,094 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:28,271 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:28,272 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:28,433 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:28,588 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:28,589 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:28,743 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:28,905 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:28,906 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:29,068 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:29,243 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:29,243 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:29,404 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:29,563 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:29,564 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:29,727 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:29,882 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:29,883 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:30,043 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:30,228 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:30,229 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:30,396 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:30,570 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:30,571 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:30,742 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:30,899 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:30,900 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:31,059 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:31,222 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:31,223 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:31,402 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:31,562 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:31,563 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:31,722 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:31,904 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:31,907 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:32,080 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:32,259 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:32,260 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:32,426 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:32,588 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:32,589 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:32,770 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:32,941 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:32,942 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:33,132 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:33,299 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:33,300 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:33,465 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:33,585 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:33,586 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:33,691 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:33,804 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:33,805 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:33,927 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:34,032 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:34,033 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:34,135 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:34,242 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:34,243 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:34,345 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:34,446 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:34,447 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:34,552 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:34,729 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:34,730 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:34,907 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:35,070 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:35,071 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:35,238 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:35,375 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:35,376 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:35,502 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:35,741 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:35,742 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:35,975 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:36,209 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:36,210 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:36,442 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:36,667 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:36,668 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:36,895 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:37,116 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:37,117 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:37,357 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:37,473 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:37,474 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:37,592 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:37,752 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:37,753 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:37,999 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:38,218 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:38,219 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:38,411 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:38,710 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:38,712 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:38,943 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:39,095 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:39,096 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:39,258 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:39,471 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:39,472 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:39,694 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:40,015 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:40,017 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:40,309 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:40,725 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:40,726 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:41,150 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:41,285 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:41,286 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:41,427 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:41,624 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:41,625 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:41,824 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:41,960 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:41,961 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:42,113 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:42,340 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:42,341 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:42,551 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:42,829 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:42,830 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:43,141 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:43,357 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:43,358 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:43,580 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:43,826 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:43,827 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:44,072 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:44,285 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:44,286 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:44,509 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:44,738 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:44,739 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:44,953 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:45,089 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:45,090 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:45,230 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:45,455 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:45,456 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:45,659 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:45,788 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:45,788 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:45,905 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:46,011 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:46,012 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:46,120 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:46,242 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:46,243 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:46,351 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:46,569 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:46,570 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:46,805 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:46,951 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:46,952 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:47,117 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:47,259 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:47,260 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:47,392 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:47,574 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:47,575 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:47,763 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:48,008 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:48,009 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:48,237 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:48,411 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:48,412 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:48,595 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:48,855 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:48,856 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:49,093 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:49,336 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:49,337 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:49,581 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:49,825 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:49,826 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:50,063 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:50,224 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:50,225 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:50,408 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:50,527 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:50,528 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:50,648 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:50,807 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:50,808 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:50,978 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:51,108 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:51,109 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:51,259 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:51,469 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:51,471 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:51,703 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:51,953 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:51,954 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:52,208 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:52,470 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:52,471 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:52,742 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:52,924 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:52,925 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:53,076 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:53,319 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:53,320 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:53,572 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:53,686 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:53,687 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:53,805 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:53,928 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:53,929 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:54,057 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:54,304 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:54,305 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:54,555 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:54,677 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:54,678 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:54,793 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:55,038 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:55,039 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:55,274 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:55,394 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:55,395 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:55,510 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:55,625 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:55,626 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:55,757 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:55,895 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:55,896 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:56,032 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:56,180 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:56,181 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:56,331 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:56,456 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:56,457 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:56,575 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:56,811 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:56,812 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:57,072 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:57,234 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:57,235 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:57,377 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:57,580 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:57,581 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:57,782 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:58,067 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:58,068 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:58,327 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:58,455 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:58,456 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:58,574 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:58,775 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:58,776 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:58,981 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:59,246 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:59,248 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:59,514 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:59,669 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:59,670 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:56:59,836 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:56:59,960 : INFO : Warming up finished.\n",
      "2022-02-12 19:56:59,961 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:00,089 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:00,205 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:00,205 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:00,326 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:00,565 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:00,566 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:00,789 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:01,072 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:01,073 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:01,375 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:01,585 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:01,586 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:01,802 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:01,943 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:01,944 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:02,088 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:02,340 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:02,341 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:02,583 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:02,833 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:02,834 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:03,095 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:03,315 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:03,316 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:03,535 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:03,913 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:03,914 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:04,372 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:04,567 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:04,568 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:04,760 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:04,951 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:04,952 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:05,142 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:05,357 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:05,358 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:05,560 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:05,760 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:05,761 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:05,958 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:06,192 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:06,193 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:06,418 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:06,634 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:06,635 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:06,837 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:07,035 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:07,036 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:07,223 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:07,503 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:07,504 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:07,774 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:07,935 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:07,936 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:08,086 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:08,232 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:08,234 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:08,378 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:08,523 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:08,524 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:08,670 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:08,813 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:08,814 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:08,975 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:09,169 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:09,170 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:09,389 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:09,641 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:09,642 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:09,882 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:10,225 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:10,226 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:10,624 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:10,800 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:10,801 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:10,982 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:11,188 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:11,188 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:11,399 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:11,670 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:11,671 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:11,922 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:12,178 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:12,180 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:12,463 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:12,634 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:12,636 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:12,805 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:13,051 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:13,052 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:13,311 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:13,528 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:13,529 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:13,739 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:13,956 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:13,957 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:14,171 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:14,422 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:14,424 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:14,698 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:14,904 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:14,905 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:15,114 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:15,398 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:15,399 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:15,674 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:15,901 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:15,902 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:16,110 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:16,327 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:16,328 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:16,547 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:16,787 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:16,788 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:17,009 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:17,260 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:17,261 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:17,511 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:17,717 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:17,718 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:17,930 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:18,105 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:18,106 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:18,289 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:18,353 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:18,354 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:18,425 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:18,528 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:18,529 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 19:57:18,623 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 19:57:18,850 : INFO : Warming up finished.\n",
      "2022-02-12 19:57:18,852 : INFO : Texts in the current batch: 1\n"
     ]
    }
   ],
   "source": [
    "df_answers['text_v'] = df_answers['text'].apply(lambda v: get_text_vectors([v])[0])\n",
    "df_questions['text_v'] = df_questions['text'].apply(lambda v: get_text_vectors([v])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы оценить качество алгоритма, нам нужна метрика качества.  \n",
    "Применим `top_k_accuracy_score` из пакета `scikit-learn`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21390374331550802"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels = df_answers['id'].values\n",
    "\n",
    "y_true = [df_positive[df_positive['question'] == q_id]['answer_1'].values[0]\n",
    "          for q_id in df_questions['id'].values]\n",
    "\n",
    "y_score = cosine_similarity(list(df_questions['text_v']), list(df_answers['text_v']))\n",
    "\n",
    "metrics.top_k_accuracy_score(y_true=y_true, y_score=y_score, k=5, labels=y_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для примера, результат, полученный на модели FastText в предыдущей теме этого курса (2.4.4. Скринкаст \"Оценка семантической близости вопросов и ответов с использованием модели FastText сервиса RusVectōrēs\"), был равен 0.797"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И напишем функцию для получения топ-к ответов:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_answers(q: str, k: int = 5) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    get_top_k_answers [summary]\n",
    "\n",
    "    [extended_summary]\n",
    "\n",
    "    Args:\n",
    "        q (str): Текст вопроса.\n",
    "        k (int, optional): Количество ответов. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: Результат в формате {текст_ответа: мера_близости}\n",
    "    \"\"\"\n",
    "\n",
    "    q_vect = get_text_vectors([q])\n",
    "    y_score = cosine_similarity(q_vect, list(df_answers['text_v']))[0]\n",
    "    result = {df_answers['text'].values[i]: y_score[i]\n",
    "             for i in np.argsort(y_score)[::-1][:k]}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-12 20:00:40,813 : INFO : Warming up ELMo on 1 sentences...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Вопрос: что такое евклидово пространство\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-12 20:00:41,110 : INFO : Warming up finished.\n",
      "2022-02-12 20:00:41,112 : INFO : Texts in the current batch: 1\n",
      "2022-02-12 20:00:41,387 : INFO : Warming up ELMo on 1 sentences...\n",
      "2022-02-12 20:00:41,540 : INFO : Warming up finished.\n",
      "2022-02-12 20:00:41,541 : INFO : Texts in the current batch: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мы ввели понятие абстрактного ВП. И уже начали понимать, что под ВП можно... 0.9235582505970406\n",
      "Векторные пространства, в которых задано скалярное произведение называютс... 0.923190256972104\n",
      "Мы будем говорить, что линейное пространство конечномерно, если либо оно ... 0.9208890641068799\n",
      "Размерностью векторного пространства (ВП) называется максимальное кол-во ... 0.9190545034524038\n",
      "Что опять же интересно – это то, что задав метрику – функцию расстояния, ... 0.9188150796986365\n",
      "--------------------------------------------------------------------------------\n",
      "Вопрос: в чём смысл жизни?\n",
      "Это поле рациональных чисел, с которыми мы фактически и работаем на компь... 0.8385716925544145\n",
      "Косинус угла между двумя векторами x и y вводится как отношение скалярног... 0.8313879912971116\n",
      "Данный форум не предназначен для решения организационных вопросов. Вы мож... 0.8301008166134773\n",
      "Векторные пространства, в которых задано скалярное произведение называютс... 0.8284527508454376\n",
      "Давайте дадим определение изоморфизма. Опр. Изоморфизм (от др.-греч. — «р... 0.8278115877159993\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    df_questions['text'].values[0],\n",
    "    'в чём смысл жизни?',\n",
    "]\n",
    "for q in questions:\n",
    "    print('-'*80)\n",
    "    print('Вопрос:', q)\n",
    "    for answer, score in get_top_k_answers(q=q).items():\n",
    "        print(answer[:73]+'...', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы \n",
    "\n",
    "\n",
    "1. Вектора, предобученные на больших корпусах текстов могут давать неплохой результат \"из коробки\".  \n",
    "2. Подбор оптимальной модели векторизации текста (обученной на разных корпусах) может привести к значительно лучшим результатам.  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aeea92d5cbc7b4733b7a0b2ebc427ac21a58cceab802504a0dd243d8ac63dc4a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
