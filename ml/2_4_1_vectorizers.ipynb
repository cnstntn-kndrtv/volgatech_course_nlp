{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4.1. Векторное представление единиц текста.\n",
    "\n",
    "Видеоуроки:  \n",
    "**2.4.1. Векторное представление единиц текста.**  \n",
    "2.4.2. Оценка близости двух текстов.  \n",
    "2.4.3. Модель word2vec сервиса RusVectōrēs.  \n",
    "\n",
    "Дополнительные материалы:  \n",
    "2.4.4. Скринкаст \"Оценка семантической близости вопросов и ответов с использованием модели FastText сервиса RusVectōrēs\".  \n",
    "2.4.5. Скринкаст \"Оценка семантической близости вопросов и ответов с использованием модели Elmo сервиса RusVectōrēs\".  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import numpy as np\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача - представить текст в виде числового вектора. В виде, пригодном для дальнейшей обработки алгоритмами МО.  \n",
    "Кроме этого хотелось бы учесть семантику (смысл) текста/предложения/слова.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding (Label binarizer)  \n",
    "  \n",
    "Задача - кодировать слово в вектор.  \n",
    "Самый простой способ - бинарное кодирование.  \n",
    "Число слов в корпусе равно $K$  \n",
    "Сопоставим слову с номером $j$ вектор длины $K$, все значения которого равны нулю, за исключением $K_{i}$, которое равно 1.  \n",
    "В таблице представлен пример для словаря из 3 слов.\n",
    "\n",
    "|          |  |  |  |\n",
    "|----------|:-:|:-:|--:|\n",
    "| белеет   | 1 | 0 | 0 |\n",
    "| парус    | 0 | 1 | 0 |\n",
    "| одинокий | 0 | 0 | 1 |\n",
    "  \n",
    "Просто, быстро, легко объяснить, подходит для простых задач. Активно применяется для кодирования категориальных переменных.  \n",
    "  \n",
    "Недостатки:\n",
    " - Теряется смысл слов. Чаще всего слова (единицы в векторе) сортируются в произвольном порядке (по алфавиту, по очереди следования в корпусе - этот порядок не имеет никакого отношения к смыслу слов ).  \n",
    " - Размер вектора $K$ растет с ростом словаря.  \n",
    " - Слова, отсутствующие в словаре (out of vocabulary - OOV) игнорируются.  \n",
    " - Модель жестко привязана к обучающей выборке (словам в выборке). Переиспользование модели на других задачах сложно, или даже невозможно.  \n",
    "\n",
    "\n",
    "\n",
    "Рассмотрим пример OneHot-кодирования с применением библиотеки `scikit-learn`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "белеет [[1 0 0]]\n",
      "парус [[0 0 1]]\n",
      "одинокий [[0 1 0]]\n",
      "ничоси [[0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "binarizer = LabelBinarizer()\n",
    "words = ['белеет', 'парус', 'одинокий']\n",
    "binarizer.fit(words)\n",
    "\n",
    "for w in words:\n",
    "    print(w, binarizer.transform([w]))\n",
    "\n",
    "# OOV\n",
    "oov_w = 'ничоси'\n",
    "print(oov_w, binarizer.transform([oov_w]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представление текста - функция от векторов слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "белеет парус одинокий ничоси [1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "doc_tokens = words + [oov_w]\n",
    "v = binarizer.transform(doc_tokens).any(axis=1) * 1\n",
    "print(' '.join(doc_tokens), v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count vectorizer  \n",
    "\n",
    "Задача - кодировать текст документа в вектор.  \n",
    "Число слов в корпусе равно $K$  \n",
    "Сопоставим документу с номером $j$ вектор длины $K$. Значение $K_{i}$ соответствует количеству (абсолютной частоте) встречаемости слова $i$ в тексте $j$.  \n",
    "Смысл документа представлен частотой слов этого документа.  \n",
    "  \n",
    "Недостатки:\n",
    "Недостатки:\n",
    " - OOV слова игнорируются.  \n",
    " - Размер вектора $K$ растет с ростом словаря.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Словарь: ['дрыгает' 'зайчик' 'ножкой' 'скачет']\n",
      "Зайчик ножкой дрыгает. [[1 1 1 0]]\n",
      "Зайчик скачет и ножкой дрыгает. Дрыгает и скачет. [[2 1 1 2]]\n",
      "OOV! Отсель грозить мы будем шведу. [[0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpora = [\n",
    "    \"Зайчик ножкой дрыгает.\",\n",
    "    \"Зайчик скачет и ножкой дрыгает. Дрыгает и скачет.\",\n",
    "]\n",
    "\n",
    "# Параметры по умолчанию разбивают текст на токены длиной не менее 2 символов.\n",
    "# в примере ниже `и` будет проигнорирован.\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit(corpora)\n",
    "\n",
    "print('Словарь:', count_vectorizer.get_feature_names_out())\n",
    "\n",
    "for doc in corpora:\n",
    "    print(doc, count_vectorizer.transform([doc]).toarray())\n",
    "\n",
    "oov_text = \"Отсель грозить мы будем шведу.\"\n",
    "print('OOV!', oov_text, count_vectorizer.transform([oov_text]).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы\n",
    "\n",
    "- Векторизация - это приведения текста в вид, пригодный для задач машинного обучения.  \n",
    "- Самыми простыми способами являются бинарное кодирование и подсчет частот слов.  \n",
    "- Простые методы часто применяют для простых задач, но они всё еще не позволяют учитывать семантику текста.  \n",
    "- Перечисленные методы выдают вектор текста размерностью Н, где Н зависит от количества слов в документах.  \n",
    "- Описанные простые методы жестко привязаны к данным, на которых они обучались. Переиспользование модели в других задачах, на других текстах затруднительно.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дополнительные материалы.  \n",
    "  \n",
    "https://youtu.be/zoPutREr9UU. Андрей Кутузов - Дистрибутивно-семантические модели языка и их применение  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aeea92d5cbc7b4733b7a0b2ebc427ac21a58cceab802504a0dd243d8ac63dc4a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
